# wechat_daily_bot/museum_scraper.py

import requests
from bs4 import BeautifulSoup

def get_latest_museum_notices(max_pages=10):
    base_url = "https://njggzy.nanjing.gov.cn/njweb/column/38257?pageNo={}"
    keyword = "åšç‰©é¦†"
    headers = {
        "User-Agent": "Mozilla/5.0"
    }
    
    results = []
    
    for page in range(1, max_pages + 1):
        url = base_url.format(page)
        resp = requests.get(url, headers=headers, timeout=8)
        if resp.status_code != 200:
            continue
        soup = BeautifulSoup(resp.text, 'html.parser')
        items = soup.select('div.article-list ul li')  # æ ¹æ®ç½‘é¡µç»“æ„è°ƒæ•´
        
        for item in items:
            a = item.find('a')
            if a and keyword in a.text:
                title = a.text.strip()
                href = a['href']
                full_url = href if href.startswith('http') else f"https://njggzy.nanjing.gov.cn{href}"
                results.append(f"{title} ğŸ‘‰ {full_url}")
        
        if len(results) >= 3:
            break
    
    return results[:3] if results else ["æš‚æ— åšç‰©é¦†ç›¸å…³å…¬å‘Š"]


